{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05ae56d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import hypll\n",
    "from hypll.manifolds.poincare_ball import Curvature, PoincareBall\n",
    "from hypll.optim import RiemannianAdam\n",
    "import hypll.nn as hnn\n",
    "from hypll.tensors import TangentTensor\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import argparse\n",
    "from pyramid import create_pyramid\n",
    "from continuous_maze import bfs, gen_traj, plot_traj, ContinuousGridEnvironment, TrajectoryDataset, LabelDataset\n",
    "from hyperbolic_networks import HyperbolicMLP, hyperbolic_infoNCE_loss, manifold_map\n",
    "from networks import StateActionEncoder, StateEncoder, CategoricalEncoder, infoNCE_loss\n",
    "import os\n",
    "\n",
    "import wandb\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "def evaluate(maze, num_trials, encoder1, encoder2, manifold, max_steps=100, hyperbolic=False, eps=10., step_size=0.5, verbose=False):\n",
    "    valid_indices = np.argwhere(maze == 0)\n",
    "    np.random.shuffle(valid_indices)\n",
    "    \n",
    "    results = []\n",
    "    for i in range(num_trials):\n",
    "        with torch.no_grad():\n",
    "            start, end = np.random.randint(0, len(valid_indices), size=2)\n",
    "            start = tuple(valid_indices[start])\n",
    "            end = tuple(valid_indices[end])\n",
    "            \n",
    "            goal = torch.tensor(end).to(torch.float32).to(device).unsqueeze(0)\n",
    "            # if hyperbolic:\n",
    "            #     goal = manifold_map(goal, manifold=manifold)\n",
    "            goal = encoder2(goal)\n",
    "            \n",
    "            # print(start)\n",
    "            env = ContinuousGridEnvironment(maze, start, {})\n",
    "            \n",
    "            def reached(cur_pos, goal_pos):\n",
    "                # print(f'cur pos: {cur_pos}')\n",
    "                cur_pos = (int(cur_pos[0]), int(cur_pos[1]))\n",
    "                goal_pos = (int(goal_pos[0]), int(goal_pos[1]))\n",
    "                return cur_pos == goal_pos\n",
    "            \n",
    "            def step():\n",
    "                cur_pos = env.agent_position\n",
    "                if verbose:\n",
    "                    print(f'cur_pos: {cur_pos}, goal: {goal}')\n",
    "                activations = []\n",
    "                angles = torch.linspace(0., 2 * torch.pi, 16)\n",
    "                for a in angles:\n",
    "                    action = torch.tensor([torch.sin(a), torch.cos(a)])\n",
    "                    cur = torch.tensor([cur_pos[0], cur_pos[1], torch.sin(a), torch.cos(a)]).to(device, torch.float32)\n",
    "                    # if hyperbolic:\n",
    "                    #     cur = manifold_map(cur, manifold)\n",
    "                    cur = encoder1(cur)\n",
    "\n",
    "                    # MANIFOLD EVAL\n",
    "                    if hyperbolic:\n",
    "                        activations.append((action, -manifold.dist(x=cur, y=goal)))\n",
    "                    else:\n",
    "                        activations.append((action, -torch.norm(cur - goal)))\n",
    "                        \n",
    "            \n",
    "\n",
    "                best_action = activations[np.argmax([x[1].cpu() for x in activations])][0]\n",
    "                angle = np.arctan2(best_action[0], best_action[1]) + np.random.normal() * eps * (2 * np.pi / 360)\n",
    "                best_action = torch.tensor(np.array([np.sin(angle), np.cos(angle)]))\n",
    "                env.move_agent(best_action)\n",
    "                # print(f'agent position: {env.agent_position}')\n",
    "                \n",
    "                \n",
    "            def SPL(maze, start, end, num_steps, success): # Success weighted by (normalized inverse) Path Length\n",
    "                if not success:\n",
    "                    return 0\n",
    "                else:\n",
    "                    p = num_steps * step_size\n",
    "                    l = len(bfs(maze, start, end))\n",
    "                    return (l / max(p, l))\n",
    "            \n",
    "            steps = 0\n",
    "            while not reached(env.agent_position, end):\n",
    "                if steps > max_steps:\n",
    "                    break\n",
    "                step()\n",
    "                steps += 1\n",
    "                \n",
    "            result = (not reached(env.agent_position, end), steps, SPL(maze, start, end, steps, reached(env.agent_position, end)))\n",
    "            if verbose:\n",
    "                print(reached(env.agent_position, end))\n",
    "                print(f'start: {start}, goal: {end}, end_pos: {env.agent_position}, steps: {steps}')\n",
    "                print(results)\n",
    "                \n",
    "            results.append(result)\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def get_maze(name):\n",
    "    maze = np.zeros((10, 10))\n",
    "    \n",
    "    if 'blank' in name:\n",
    "        print('blank maze')\n",
    "        maze = np.zeros((10, 10))\n",
    "    elif 'slit' in name:\n",
    "        print('slit maze')\n",
    "        maze = np.zeros((11, 11))\n",
    "        maze[:,5] = 1\n",
    "        maze[5, 5] = 0\n",
    "    elif 'blocker' in name:\n",
    "        maze = np.zeros((11, 11))\n",
    "        maze[3,:] = 1\n",
    "        maze[3, 10] = 0\n",
    "    elif 'nested_pyramid' in name:\n",
    "        maze = create_pyramid(np.zeros((2, 2)), 2)[0]\n",
    "    else:\n",
    "        maze = create_pyramid(np.zeros((2, 2)), 1)[0]\n",
    "\n",
    "    return maze\n",
    "\n",
    "def save_models(encoder1, encoder2, best_encoder1, best_encoder2, epoch, best_epoch, name=''):\n",
    "    os.makedirs('models', exist_ok=True)\n",
    "    torch.save(encoder1.state_dict(), f'models/{name}_encoder1_epoch_{epoch}.pth')\n",
    "    torch.save(encoder2.state_dict(), f'models/{name}_encoder2_epoch_{epoch}.pth')\n",
    "    torch.save(best_encoder1, f'models/{name}_best_encoder1_epoch_{best_epoch}.pth')\n",
    "    torch.save(best_encoder2, f'models/{name}_best_encoder2_epoch_{best_epoch}.pth')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9918e210",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "maze = get_maze('blocker')\n",
    "\n",
    "wandb.init(\n",
    "    project='noproject', \n",
    "    name='noname', \n",
    "    # Track hyperparameters and run metadata\n",
    "    config={\n",
    "        \"embedding_dim\": 8,\n",
    "        \"eval_trials\": 100,\n",
    "        \"max_steps\": 100,\n",
    "        \"hyperbolic\": False,\n",
    "        \"num_epochs\": 16,\n",
    "        \"temperature\": 0.1,\n",
    "        \"batch_size\": 64,\n",
    "        \"num_negatives\": 64,\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"architecture\": \"MLP\",\n",
    "        \"maze\": maze,\n",
    "        \"num_trajectories\": 1000,\n",
    "        \"maze_type\": 'blocker',\n",
    "        \"gamma\":0.1,\n",
    "        \"hyp_layers\": 1\n",
    "    }\n",
    ")\n",
    "\n",
    "# configs\n",
    "config = wandb.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f51e970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_dim': 8, 'eval_trials': 100, 'max_steps': 100, 'hyperbolic': False, 'num_epochs': 16, 'temperature': 0.1, 'batch_size': 64, 'num_negatives': 64, 'learning_rate': 0.001, 'architecture': 'MLP', 'maze': '[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\\n [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.]\\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]', 'num_trajectories': 1000, 'maze_type': 'blocker', 'gamma': 0.1, 'hyp_layers': 1}\n",
      "gamma: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_807698/3385964954.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  anchor = torch.tensor(anchor).to(device, torch.float32)\n",
      "/tmp/ipykernel_807698/3385964954.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  positive = torch.tensor(positive).to(device, torch.float32)\n",
      "/tmp/ipykernel_807698/3385964954.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives = torch.tensor(negatives).to(device, torch.float32)\n",
      "/tmp/ipykernel_807698/3385964954.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s_anchor = torch.tensor(s_anchor).to(device)\n",
      "/tmp/ipykernel_807698/3385964954.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s_positive = torch.tensor(s_positive).to(device, torch.float32)\n",
      "/tmp/ipykernel_807698/3385964954.py:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s_negatives = torch.tensor(s_negatives).to(device, torch.float32)\n",
      "/tmp/ipykernel_807698/3385964954.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s_neg_cats = torch.tensor(s_neg_cats).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 12.599339246749878, SPL: 0.08655559494269172, Failure %: 0.9\n",
      "Epoch 2, Loss: 10.938816964626312, SPL: 0.1350411914382147, Failure %: 0.83\n",
      "Epoch 3, Loss: 10.658222734928131, SPL: 0.2329696693758978, Failure %: 0.65\n",
      "Epoch 4, Loss: 10.440049171447754, SPL: 0.22008432397872507, Failure %: 0.67\n",
      "Epoch 5, Loss: 10.194572269916534, SPL: 0.18762195864005918, Failure %: 0.74\n",
      "Epoch 6, Loss: 10.127788543701172, SPL: 0.28371740034557863, Failure %: 0.63\n",
      "Epoch 7, Loss: 10.019772589206696, SPL: 0.28327553253113025, Failure %: 0.62\n",
      "Epoch 8, Loss: 9.837863385677338, SPL: 0.29450731530111196, Failure %: 0.59\n",
      "Epoch 9, Loss: 9.847705364227295, SPL: 0.18088182866608168, Failure %: 0.73\n",
      "Epoch 10, Loss: 9.821453154087067, SPL: 0.2658004419441617, Failure %: 0.63\n",
      "Epoch 11, Loss: 9.875501453876495, SPL: 0.16753876229040351, Failure %: 0.75\n",
      "Epoch 12, Loss: 9.800004124641418, SPL: 0.32594911908023333, Failure %: 0.52\n",
      "Epoch 13, Loss: 9.660109221935272, SPL: 0.25685650699538276, Failure %: 0.65\n",
      "Epoch 14, Loss: 9.63688349723816, SPL: 0.368898650938666, Failure %: 0.45\n",
      "Epoch 15, Loss: 9.640058398246765, SPL: 0.12603392522937068, Failure %: 0.82\n",
      "Epoch 16, Loss: 9.639495015144348, SPL: 0.37424219590583185, Failure %: 0.52\n"
     ]
    }
   ],
   "source": [
    "print(config)\n",
    "manifold = PoincareBall(c=Curvature(value=0.1, requires_grad=True))\n",
    "\n",
    "dataset = TrajectoryDataset(maze, config.num_trajectories, embedding_dim=config.embedding_dim, num_negatives=10, gamma=config.gamma)\n",
    "dataloader = DataLoader(dataset, batch_size=config.batch_size, shuffle=True, num_workers=1)\n",
    "street_dataset = LabelDataset(maze, size=1000, embedding_dim=config.embedding_dim, num_negatives=10)\n",
    "street_dataloader = DataLoader(street_dataset, batch_size=config.batch_size, shuffle=True, num_workers=1)\n",
    "\n",
    "\n",
    "encoder1 = StateActionEncoder(config.embedding_dim).to(device)\n",
    "encoder2 = StateEncoder(config.embedding_dim).to(device)\n",
    "street_encoder = CategoricalEncoder(street_dataset.num_categories, config.embedding_dim)\n",
    "optimizer = optim.Adam(list(encoder1.parameters()) + list(encoder2.parameters()), lr=config.learning_rate)\n",
    "\n",
    "best_spl = 0\n",
    "best_encoder1 = encoder1.state_dict()\n",
    "best_encoder2 = encoder2.state_dict()\n",
    "best_epoch = 0\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(config.num_epochs):\n",
    "    total_loss = 0\n",
    "    street_iterator = iter(street_dataloader)\n",
    "    \n",
    "    for anchor, positive, negatives in dataloader:\n",
    "        try:\n",
    "            s_anchor, s_positive, s_negatives, s_neg_cats = next(street_iterator)\n",
    "        except StopIteration:\n",
    "            street_iterator = iter(street_dataloader)\n",
    "            s_anchor, s_positive, s_negatives, s_neg_cats = next(street_iterator)\n",
    "\n",
    "        # (s,a) <-> (s)\n",
    "        anchor = torch.tensor(anchor).to(device, torch.float32)\n",
    "        positive = torch.tensor(positive).to(device, torch.float32)\n",
    "        negatives = torch.tensor(negatives).to(device, torch.float32)\n",
    "\n",
    "\n",
    "        anchor_enc = encoder1(anchor) # takes state, action tuple\n",
    "        positive_enc = encoder2(positive) # takes state\n",
    "        negatives_enc = encoder2(negatives)\n",
    "\n",
    "        cur_state = anchor[:,[0,1]]\n",
    "        angle = torch.arctan2(anchor[:,2], anchor[:,3])\n",
    "\n",
    "        negative_actions = (angle + torch.pi)[:,None] + (torch.rand(config.num_negatives)[None,:].to(device) - 0.5) * (3 * torch.pi / 2)\n",
    "        negative_dirs = torch.stack([torch.sin(negative_actions), torch.cos(negative_actions)]).moveaxis(0, -1)\n",
    "        negative_full = torch.cat((cur_state.unsqueeze(1).expand(-1, config.num_negatives, -1), negative_dirs), dim=-1).to(device)\n",
    "        neg_action_enc = encoder1(negative_full)\n",
    "\n",
    "        action_loss = infoNCE_loss(positive_enc, anchor_enc, neg_action_enc, config.temperature, metric_type=1)\n",
    "        future_loss = infoNCE_loss(anchor_enc, positive_enc, negatives_enc, config.temperature, metric_type=1)\n",
    "\n",
    "        loss = action_loss + future_loss\n",
    "\n",
    "        s_anchor = torch.tensor(s_anchor).to(device)\n",
    "        s_positive = torch.tensor(s_positive).to(device, torch.float32)\n",
    "        s_negatives = torch.tensor(s_negatives).to(device, torch.float32)\n",
    "        s_neg_cats = torch.tensor(s_neg_cats).to(device)\n",
    "\n",
    "        s_anchor_enc = street_encoder(s_anchor) # takes state, action tuple\n",
    "        s_positive_enc = encoder2(s_positive) # takes state\n",
    "        s_negatives_enc = encoder2(s_negatives)\n",
    "        s_neg_cats_enc = street_encoder(s_neg_cats)\n",
    "\n",
    "        s_loss = infoNCE_loss(s_anchor_enc, s_positive_enc, s_negatives_enc, config.temperature, metric_type=1)\n",
    "        s2_loss = infoNCE_loss(s_positive_enc, s_anchor_enc, s_neg_cats_enc, config.temperature, metric_type=1)\n",
    "        loss += s_loss + s2_loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    loss = total_loss / len(dataloader)\n",
    "    evals = evaluate(maze, config.eval_trials, encoder1, encoder2, manifold, max_steps=config.max_steps, hyperbolic=config.hyperbolic, eps=50.)\n",
    "    acc = np.mean([x[2] for x in evals])\n",
    "    fail = np.mean([x[0] for x in evals])\n",
    "\n",
    "    metrics = {\n",
    "        \"epoch\": epoch + 1,\n",
    "        \"loss\": loss,\n",
    "        \"spl\": acc,\n",
    "        \"fail\": fail\n",
    "    }\n",
    "    wandb.log(metrics)\n",
    "\n",
    "    if acc > best_spl:\n",
    "        best_spl = acc\n",
    "        best_encoder1 = encoder1.state_dict()\n",
    "        best_encoder2 = encoder2.state_dict()\n",
    "        best_epoch = epoch + 1\n",
    "\n",
    "#     if epoch % 32 == 0:\n",
    "#         save_models(encoder1, encoder2, best_encoder1, best_encoder2, epoch + 1, best_epoch, experiment_name)\n",
    "\n",
    "    print(f'Epoch {epoch+1}, Loss: {loss}, SPL: {acc}, Failure %: {fail}')\n",
    "\n",
    "# save_models(encoder1, encoder2, best_encoder1, best_encoder2, epoch + 1, best_epoch, experiment_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89414f75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11,\n",
       " array([0.23100757, 0.06919214]),\n",
       " array([[ 8.82555558,  2.38111242],\n",
       "        [ 3.60719127,  7.32444709],\n",
       "        [10.45399338,  9.69942179],\n",
       "        [ 5.9742097 ,  4.98081709],\n",
       "        [ 8.85545035,  2.13547802],\n",
       "        [ 4.86092919, 10.31306719],\n",
       "        [ 4.65853024,  5.35934154],\n",
       "        [ 8.33903978,  6.26368967],\n",
       "        [ 2.60227142,  9.98562671],\n",
       "        [ 1.16966521,  1.09311244]]),\n",
       " array([ 5,  5,  5, 17, 19, 12, 13, 21,  5,  3]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "street_dataset[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28510c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "maze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103d0351",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hypll [~/.conda/envs/hypll/]",
   "language": "python",
   "name": "conda_hypll"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
