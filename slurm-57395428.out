wandb: Tracking run with wandb version 0.17.3
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
/home/yongweic/.conda/envs/hypll/lib/python3.10/site-packages/torch/_compile.py:24: UserWarning: optimizer contains a parameter group with duplicate parameters; in future, this will cause an error; see github.com/pytorch/pytorch/issues/40967 for more information
  return torch._dynamo.disable(fn, recursive)(*args, **kwargs)
{'project': 'efficient_blocker', 'custom': '1', 'hyperbolic': True, 'embedding_dim': 4, 'hyp_layers': 2, 'num_epochs': 64, 'num_trajectories': 5000, 'batch_size': 128, 'num_negatives': 32, 'max_steps': 50, 'num_workers': 24, 'learning_rate': 0.001, 'maze_type': 'nested_pyramid', 'gamma': 0.1, 'order_name': '', 'eval_trials': 10, 'temperature': 0.1, 'architecture': 'MLP'}
no order
gamma: 0.1
[16.45243779  7.85228802] -> [28.51704618  9.98068593]
[30.40373738 11.92349548] -> [24.60280225 10.38626546]
[30.48511875 30.54415286] -> [24.50106104 28.47802703]
[30.44039506 12.88119072] -> [10.45990181 29.42802801]
[26.43859027 20.51374212] -> [31.785001   20.46671729]
[26.09997216 19.49292989] -> [32.45542099 27.99922645]
[12.51645947 19.49519641] -> [10.47638419 17.54522305]
[25.60518496 16.52453049] -> [24.60841633 16.44898931]
[20.47952299 23.25253024] -> [21.92013    19.31421478]
[32.39183923 30.42325942] -> [15.51015114  3.63406539]
starting...
Epoch 0 complete. Average: 11.78 batches/second
Epoch 1, Loss: 6.634362900257111
Epoch 1 complete. Average: 13.69 batches/second
Epoch 2, Loss: 6.024331212043762
Epoch 2, Batch 100: 13.90 batches/second
Epoch 2 complete. Average: 14.48 batches/second
Epoch 3, Loss: 5.9067341685295105
Epoch 3 complete. Average: 14.88 batches/second
Epoch 4, Loss: 5.781681263446808
Epoch 4, Batch 200: 15.09 batches/second
Epoch 4 complete. Average: 15.00 batches/second
Epoch 5, Loss: 5.7184359431266785
Epoch 5 complete. Average: 15.25 batches/second
Epoch 6, Loss: 5.689787971973419
Epoch 6 complete. Average: 15.40 batches/second
Epoch 7, Loss: 5.798486411571503
Epoch 7, Batch 300: 15.36 batches/second
Epoch 7 complete. Average: 15.51 batches/second
Epoch 8, Loss: 5.6750738501548765
Epoch 8 complete. Average: 15.61 batches/second
Epoch 9, Loss: 5.652185082435608
Epoch 9, Batch 400: 15.74 batches/second
Epoch 9 complete. Average: 15.69 batches/second
Epoch 10, Loss: 5.6303224802017215
Epoch 10 complete. Average: 15.74 batches/second
Epoch 11, Loss: 5.645451605319977
Epoch 11 complete. Average: 15.88 batches/second
Epoch 12, Loss: 5.585759603977204
Epoch 12, Batch 500: 15.83 batches/second
Epoch 12 complete. Average: 15.91 batches/second
Epoch 13, Loss: 5.6286509275436405
Epoch 13 complete. Average: 15.93 batches/second
Epoch 14, Loss: 5.655560576915741
Epoch 14, Batch 600: 15.99 batches/second
Epoch 14 complete. Average: 15.96 batches/second
Epoch 15, Loss: 5.598095560073853
Epoch 15 complete. Average: 16.02 batches/second
Epoch 16, Loss: 5.662102019786834
Epoch 16 complete. Average: 16.04 batches/second
Epoch 17, Loss: 5.578679263591766
Epoch 17, Batch 700: 16.04 batches/second
Epoch 17 complete. Average: 16.13 batches/second
Epoch 18, Loss: 5.548299741744995
Epoch 18 complete. Average: 16.14 batches/second
Epoch 19, Loss: 5.564128935337067
Epoch 19, Batch 800: 16.17 batches/second
Epoch 19 complete. Average: 16.15 batches/second
Epoch 20, Loss: 5.502280151844024
Epoch 20 complete. Average: 16.07 batches/second
Epoch 21, Loss: 5.595923638343811
Epoch 21 complete. Average: 16.09 batches/second
Epoch 22, Loss: 5.497655916213989
Epoch 22, Batch 900: 16.08 batches/second
Epoch 22 complete. Average: 16.15 batches/second
Epoch 23, Loss: 5.601619815826416
Epoch 23 complete. Average: 16.20 batches/second
Epoch 24, Loss: 5.494581651687622
Epoch 24, Batch 1000: 16.27 batches/second
Epoch 24 complete. Average: 16.25 batches/second
Epoch 25, Loss: 5.5149466633796695
Epoch 25 complete. Average: 16.26 batches/second
Epoch 26, Loss: 5.629461300373078
Epoch 26 complete. Average: 16.25 batches/second
Epoch 27, Loss: 5.513177120685578
Epoch 27, Batch 1100: 16.22 batches/second
Epoch 27 complete. Average: 16.25 batches/second
Epoch 28, Loss: 5.510322141647339
Epoch 28 complete. Average: 16.29 batches/second
Epoch 29, Loss: 5.560060179233551
Epoch 29, Batch 1200: 16.34 batches/second
Epoch 29 complete. Average: 16.33 batches/second
Epoch 30, Loss: 5.488342726230622
Epoch 30 complete. Average: 16.33 batches/second
Epoch 31, Loss: 5.452576839923859
Epoch 31 complete. Average: 16.33 batches/second
Epoch 32, Loss: 5.575002443790436
Epoch 32, Batch 1300: 16.30 batches/second
Epoch 32 complete. Average: 16.32 batches/second
Epoch 33, Loss: 5.45626300573349, SPL: 0.1, Failure %: 0.9
Epoch 33 complete. Average: 12.91 batches/second
Epoch 34, Loss: 5.4062375664711
Epoch 34, Batch 1400: 13.00 batches/second
Epoch 34 complete. Average: 12.99 batches/second
Epoch 35, Loss: 5.277810204029083
Epoch 35 complete. Average: 13.04 batches/second
Epoch 36, Loss: 5.1676253318786625
Epoch 36 complete. Average: 13.12 batches/second
Epoch 37, Loss: 5.3371902227401735
Epoch 37, Batch 1500: 13.13 batches/second
Epoch 37 complete. Average: 13.18 batches/second
Epoch 38, Loss: 5.163038754463196
Epoch 38 complete. Average: 13.27 batches/second
Epoch 39, Loss: 5.1076079368591305
Epoch 39, Batch 1600: 13.34 batches/second
Epoch 39 complete. Average: 13.33 batches/second
Epoch 40, Loss: 5.095702588558197
Epoch 40 complete. Average: 13.39 batches/second
Epoch 41, Loss: 5.059131753444672
Epoch 41 complete. Average: 13.45 batches/second
Epoch 42, Loss: 5.032745623588562
Epoch 42, Batch 1700: 13.46 batches/second
Epoch 42 complete. Average: 13.50 batches/second
Epoch 43, Loss: 4.845728719234467
Epoch 43 complete. Average: 13.53 batches/second
Epoch 44, Loss: 4.87790732383728
Epoch 44, Batch 1800: 13.59 batches/second
Epoch 44 complete. Average: 13.58 batches/second
Epoch 45, Loss: 4.904401957988739
Epoch 45 complete. Average: 13.63 batches/second
Epoch 46, Loss: 4.805541694164276
Epoch 46 complete. Average: 13.70 batches/second
Epoch 47, Loss: 5.148516607284546
Epoch 47, Batch 1900: 13.71 batches/second
Epoch 47 complete. Average: 13.76 batches/second
Epoch 48, Loss: 4.730689036846161
Epoch 48 complete. Average: 13.80 batches/second
Epoch 49, Loss: 4.663903093338012
Epoch 49, Batch 2000: 13.87 batches/second
Epoch 49 complete. Average: 13.86 batches/second
Epoch 50, Loss: 4.6402682900428776
Epoch 50 complete. Average: 13.91 batches/second
Epoch 51, Loss: 4.607728147506714
Epoch 51 complete. Average: 13.95 batches/second
Epoch 52, Loss: 4.6227888584136965
Epoch 52, Batch 2100: 13.96 batches/second
Epoch 52 complete. Average: 13.99 batches/second
Epoch 53, Loss: 4.588647985458374
Epoch 53 complete. Average: 14.02 batches/second
Epoch 54, Loss: 4.554710793495178
Epoch 54, Batch 2200: 14.07 batches/second
Epoch 54 complete. Average: 14.06 batches/second
Epoch 55, Loss: 4.615765917301178
Epoch 55 complete. Average: 14.11 batches/second
Epoch 56, Loss: 4.429114067554474
Epoch 56 complete. Average: 14.14 batches/second
Epoch 57, Loss: 4.583606427907943
Epoch 57, Batch 2300: 14.14 batches/second
Epoch 57 complete. Average: 14.17 batches/second
Epoch 58, Loss: 4.347880858182907
Epoch 58 complete. Average: 14.22 batches/second
Epoch 59, Loss: 4.441833436489105
Epoch 59, Batch 2400: 14.25 batches/second
Epoch 59 complete. Average: 14.25 batches/second
Epoch 60, Loss: 4.457787173986435
Epoch 60 complete. Average: 14.28 batches/second
Epoch 61, Loss: 4.472867047786712
Epoch 61 complete. Average: 14.32 batches/second
Epoch 62, Loss: 4.576128607988357
Epoch 62, Batch 2500: 14.32 batches/second
Epoch 62 complete. Average: 14.35 batches/second
Epoch 63, Loss: 4.486363798379898
Epoch 63 complete. Average: 14.38 batches/second
Epoch 64, Loss: 4.327476781606674
Wrote profile results to train.py.lprof
Inspect results with:
python -m line_profiler -rmt "train.py.lprof"
wandb: 
wandb: Run history:
wandb: epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  fail ▁
wandb:  loss █▆▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▂▃▂▂▂▂▂▂▁▁▂▁
wandb:   spl ▁
wandb: 
wandb: Run summary:
wandb: epoch 64
wandb:  fail 0.9
wandb:  loss 4.32748
wandb:   spl 0.1
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/yongweic/hyperbolic/wandb/offline-run-20240704_142630-g7510f7a
wandb: Find logs at: ./wandb/offline-run-20240704_142630-g7510f7a/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
