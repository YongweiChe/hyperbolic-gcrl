{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2230c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import hypll\n",
    "from hypll.manifolds.poincare_ball import Curvature, PoincareBall\n",
    "from hypll.optim import RiemannianAdam\n",
    "import hypll.nn as hnn\n",
    "from hypll.tensors import TangentTensor\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import argparse\n",
    "from pyramid import create_pyramid\n",
    "from continuous_maze import get_maze_image, bfs, gen_traj, plot_traj, ContinuousGridEnvironment, TrajectoryDataset, TrajectoryImageDataset, LabelDataset\n",
    "from hyperbolic_networks import HyperbolicMLP, hyperbolic_infoNCE_loss, manifold_map\n",
    "from networks import StateActionEncoder, StateEncoder, infoNCE_loss, FlexibleCNN, ActionNetwork\n",
    "import os\n",
    "\n",
    "import wandb\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "def evaluate(maze, num_trials, encoder1, encoder2, manifold, image_height, image_width, max_steps=100, hyperbolic=False, eps=10., step_size=0.5, verbose=False):\n",
    "    valid_indices = np.argwhere(maze == 0)\n",
    "    np.random.shuffle(valid_indices)\n",
    "    \n",
    "    results = []\n",
    "    for i in range(num_trials):\n",
    "        with torch.no_grad():\n",
    "            start, end = np.random.randint(0, len(valid_indices), size=2)\n",
    "            start = tuple(valid_indices[start])\n",
    "            end = tuple(valid_indices[end])\n",
    "            \n",
    "            goal = torch.tensor(get_maze_image(maze, end, image_height, image_width)).to(device, torch.float32).unsqueeze(0)\n",
    "            # plt.imshow(goal)[0]\n",
    "            goal = encoder2(goal)\n",
    "            \n",
    "            env = ContinuousGridEnvironment(maze, start, {})\n",
    "            \n",
    "            def reached(cur_pos, goal_pos):\n",
    "                # print(f'cur pos: {cur_pos}')\n",
    "                cur_pos = (int(cur_pos[0]), int(cur_pos[1]))\n",
    "                goal_pos = (int(goal_pos[0]), int(goal_pos[1]))\n",
    "                return cur_pos == goal_pos\n",
    "            \n",
    "            def step():\n",
    "                cur_pos = env.agent_position\n",
    "                if verbose:\n",
    "                    print(f'cur_pos: {cur_pos}, goal: {goal}')\n",
    "                image = torch.tensor(get_maze_image(maze, cur_pos, image_height, image_width)).to(device, torch.float32). unsqueeze(0)\n",
    "                activations = []\n",
    "                angles = torch.linspace(0., 2 * torch.pi, 16)\n",
    "                for a in angles:\n",
    "                    action = torch.tensor([torch.sin(a), torch.cos(a)]).unsqueeze(0).to(device, torch.float32)\n",
    "                    # cur = torch.tensor([torch.sin(a), torch.cos(a)]).to(device, torch.float32)\n",
    "                    # if hyperbolic:\n",
    "                    #     cur = manifold_map(cur, manifold)\n",
    "                    # print(f'action: {action}')\n",
    "                    cur = encoder1(image, action) # YOU CAN OPTIMIZE THIS\n",
    "                    # print(f'encoded: {cur.shape}')\n",
    "\n",
    "                    # MANIFOLD EVAL\n",
    "                    if hyperbolic:\n",
    "                        activations.append((action, -manifold.dist(x=cur, y=goal)))\n",
    "                    else:\n",
    "                        activations.append((action, -torch.norm(cur - goal)))\n",
    "                        \n",
    "\n",
    "                best_action = activations[np.argmax([x[1].cpu() for x in activations])][0][0].cpu()\n",
    "                # print(f'best action: {best_action}')\n",
    "                angle = np.arctan2(best_action[0], best_action[1]) + np.random.normal() * eps * (2 * np.pi / 360)\n",
    "                best_action = torch.tensor(np.array([np.sin(angle), np.cos(angle)]))\n",
    "                env.move_agent(best_action)\n",
    "                # print(f'agent position: {env.agent_position}')\n",
    "                \n",
    "                \n",
    "            def SPL(maze, start, end, num_steps, success): # Success weighted by (normalized inverse) Path Length\n",
    "                if not success:\n",
    "                    return 0\n",
    "                else:\n",
    "                    p = num_steps * step_size\n",
    "                    l = len(bfs(maze, start, end))\n",
    "                    return (l / max(p, l))\n",
    "            \n",
    "            steps = 0\n",
    "            while not reached(env.agent_position, end):\n",
    "                if steps > max_steps:\n",
    "                    break\n",
    "                step()\n",
    "                steps += 1\n",
    "                \n",
    "            result = (not reached(env.agent_position, end), steps, SPL(maze, start, end, steps, reached(env.agent_position, end)))\n",
    "            if verbose:\n",
    "                print(reached(env.agent_position, end))\n",
    "                print(f'start: {start}, goal: {end}, end_pos: {env.agent_position}, steps: {steps}')\n",
    "                print(results)\n",
    "                \n",
    "            results.append(result)\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def save_models(encoder1, encoder2, best_encoder1, best_encoder2, epoch, best_epoch, name=''):\n",
    "    os.makedirs('models', exist_ok=True)\n",
    "    torch.save(encoder1.state_dict(), f'models/{name}_encoder1_epoch_{epoch}.pth')\n",
    "    torch.save(encoder2.state_dict(), f'models/{name}_encoder2_epoch_{epoch}.pth')\n",
    "    torch.save(best_encoder1.state_dict(), f'models/{name}_best_encoder1_epoch_{best_epoch}.pth')\n",
    "    torch.save(best_encoder2.state_dict(), f'models/{name}_best_encoder2_epoch_{best_epoch}.pth')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96b8a366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "150bc29d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2303149/1139506588.py:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  anchor = torch.tensor(anchor).to(device, torch.float32) # 4 vector\n",
      "/tmp/ipykernel_2303149/1139506588.py:81: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  positive = torch.tensor(positive).to(device, torch.float32) # image\n",
      "/tmp/ipykernel_2303149/1139506588.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives = torch.tensor(negatives).to(device, torch.float32) # image\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 56222.66076660156, SPL: 0.4, Failure %: 0.6\n",
      "Epoch 2, Loss: 15011.021667480469, SPL: 0.2, Failure %: 0.8\n",
      "Epoch 3, Loss: 6568.204650878906, SPL: 0.0, Failure %: 1.0\n",
      "Epoch 4, Loss: 1888.8054809570312, SPL: 0.0, Failure %: 1.0\n",
      "Epoch 5, Loss: 406.5756721496582, SPL: 0.0, Failure %: 1.0\n",
      "Epoch 6, Loss: 113.92646217346191, SPL: 0.0, Failure %: 1.0\n",
      "Epoch 7, Loss: 64.0853624343872, SPL: 0.0, Failure %: 1.0\n",
      "Epoch 8, Loss: 15.430098295211792, SPL: 0.0, Failure %: 1.0\n",
      "Epoch 9, Loss: 5.793213844299316, SPL: 0.0, Failure %: 1.0\n",
      "Epoch 10, Loss: 5.514932036399841, SPL: 0.0, Failure %: 1.0\n",
      "Epoch 11, Loss: 4.848151445388794, SPL: 0.0, Failure %: 1.0\n",
      "Epoch 12, Loss: 4.9753657579422, SPL: 0.0, Failure %: 1.0\n",
      "Epoch 13, Loss: 5.012448191642761, SPL: 0.0, Failure %: 1.0\n",
      "Epoch 14, Loss: 4.952646374702454, SPL: 0.4, Failure %: 0.6\n",
      "Epoch 15, Loss: 4.998871445655823, SPL: 0.0, Failure %: 1.0\n",
      "Epoch 16, Loss: 4.910069465637207, SPL: 0.0, Failure %: 1.0\n",
      "Epoch 17, Loss: 4.928741097450256, SPL: 0.2, Failure %: 0.8\n",
      "Epoch 18, Loss: 4.9563915729522705, SPL: 0.0, Failure %: 1.0\n",
      "Epoch 19, Loss: 5.02497124671936, SPL: 0.0, Failure %: 1.0\n",
      "Epoch 20, Loss: 5.190903425216675, SPL: 0.2, Failure %: 0.8\n",
      "Epoch 21, Loss: 4.8878713846206665, SPL: 0.0, Failure %: 1.0\n",
      "Epoch 22, Loss: 5.144581198692322, SPL: 0.0, Failure %: 1.0\n",
      "Epoch 23, Loss: 4.965943098068237, SPL: 0.0, Failure %: 1.0\n",
      "Epoch 24, Loss: 4.898433089256287, SPL: 0.0, Failure %: 1.0\n"
     ]
    }
   ],
   "source": [
    "# maze = create_pyramid(np.zeros((2, 2)), 1)[0]\n",
    "maze = np.zeros((10, 10))\n",
    "# wandb.init(\n",
    "#     project=\"testing\", \n",
    "#     name='blah', \n",
    "#     # Track hyperparameters and run metadata\n",
    "#     config={\n",
    "#         \"batch_size\": 32,\n",
    "#         \"embedding_dim\": 8,\n",
    "#         \"eval_trials\": 100,\n",
    "#         \"max_steps\": 100,\n",
    "#         \"hyperbolic\": False,\n",
    "#         \"num_epochs\": 8,\n",
    "#         \"temperature\": 0.1,\n",
    "#         \"num_negatives\": 11,\n",
    "#         \"learning_rate\": 0.001,\n",
    "#         \"architecture\": \"MLP\",\n",
    "#         \"maze\": maze,\n",
    "#         \"num_trajectories\": 10000,\n",
    "#         \"maze_type\": 'blank'\n",
    "#     }\n",
    "# )\n",
    "\n",
    "class Config:\n",
    "    def __init__(self, config_dict):\n",
    "        for key, value in config_dict.items():\n",
    "            setattr(self, key, value)\n",
    "\n",
    "config={\n",
    "    \"batch_size\": 32,\n",
    "    \"embedding_dim\": 8,\n",
    "    \"eval_trials\": 5,\n",
    "    \"max_steps\": 100,\n",
    "    \"hyperbolic\": False,\n",
    "    \"num_epochs\": 24,\n",
    "    \"temperature\": 0.1,\n",
    "    \"num_negatives\": 11,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"architecture\": \"MLP\",\n",
    "    \"maze\": maze,\n",
    "    \"num_trajectories\": 100,\n",
    "    \"maze_type\": 'blank',\n",
    "    \"image_height\": 128,\n",
    "    \"image_width\": 128\n",
    "}\n",
    "config = Config(config)\n",
    "\n",
    "manifold = PoincareBall(c=Curvature(value=0.1, requires_grad=True))\n",
    "\n",
    "dataset = TrajectoryImageDataset(maze, config.num_trajectories, embedding_dim=config.embedding_dim, num_negatives=10, image_height=config.image_height, image_width=config.image_width)\n",
    "# plt.imshow(dataset[0][1])\n",
    "# print('here')\n",
    "dataloader = DataLoader(dataset, batch_size=config.batch_size, shuffle=True, num_workers=1)\n",
    "\n",
    "# if config.hyperbolic:\n",
    "#     encoder1 = HyperbolicMLP(in_features=4, out_features=config.embedding_dim, manifold=manifold.to(device)).to(device)\n",
    "#     encoder2 = HyperbolicMLP(in_features=2, out_features=config.embedding_dim, manifold=manifold.to(device)).to(device)\n",
    "#     optimizer = RiemannianAdam(list(encoder1.parameters()) + list(encoder2.parameters()), lr=config.learning_rate)\n",
    "# else:\n",
    "#     encoder1 = StateActionEncoder(config.embedding_dim).to(device)\n",
    "#     encoder2 = StateEncoder(config.embedding_dim).to(device)\n",
    "#     optimizer = optim.Adam(list(encoder1.parameters()) + list(encoder2.parameters()), lr=config.learning_rate)\n",
    "\n",
    "\n",
    "    \n",
    "encoder2 = FlexibleCNN(3, config.embedding_dim, np.zeros((1, 3, config.image_height, config.image_width))).to(device)\n",
    "encoder1 = ActionNetwork(encoder2, config.embedding_dim).to(device)\n",
    "optimizer = optim.Adam(list(encoder1.parameters()) + list(encoder2.parameters()), lr=config.learning_rate)\n",
    "    \n",
    "best_spl = 0\n",
    "best_encoder1 = encoder1.state_dict()\n",
    "best_encoder2 = encoder2.state_dict()\n",
    "best_epoch = 0\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(config.num_epochs):\n",
    "    total_loss = 0\n",
    "    for anchor, positive, negatives in dataloader:\n",
    "        # (s,a) <-> (s)\n",
    "        anchor = torch.tensor(anchor).to(device, torch.float32) # 4 vector\n",
    "        positive = torch.tensor(positive).to(device, torch.float32) # image\n",
    "        negatives = torch.tensor(negatives).to(device, torch.float32) # image\n",
    "        # print(anchor.shape)\n",
    "        # print(f'positive: {positive.shape}, negatives: {negatives.shape}')\n",
    "        positive_enc = encoder2(positive) # takes state\n",
    "        anchor_enc = encoder1(positive, anchor[:,[2,3]]) # takes state, action tuple, need to change\n",
    "        negatives_enc = encoder2(negatives.view(-1, 3, config.image_height, config.image_width)).view(negatives.shape[0], negatives.shape[1], -1)\n",
    "        # print(f'positive_enc: {positive_enc.shape}, negatives_enc: {negatives_enc.shape}')\n",
    "\n",
    "        positive_action = anchor[:,[2,3]]\n",
    "        cur_state = anchor[:,[0,1]] \n",
    "        angle = torch.arctan2(anchor[:,2], anchor[:,3])\n",
    "\n",
    "        negative_actions = (angle + torch.pi)[:,None] + (torch.rand(config.num_negatives)[None,:].to(device) - 0.5) * (3 * torch.pi / 2)\n",
    "        negative_dirs = torch.stack([torch.sin(negative_actions), torch.cos(negative_actions)]).moveaxis(0, -1)\n",
    "        # print(f'negative_dirs: {negative_dirs.shape}')\n",
    "        # need to change torch.cat to be an image\n",
    "        # negative_full = torch.cat((cur_state.unsqueeze(1).expand(-1, config.num_negatives, -1), negative_dirs), dim=-1).to(device)\n",
    "        # print(f'full: {negative_full.shape}')\n",
    "        positive_images = positive.unsqueeze(1).expand(-1, config.num_negatives, -1, -1, -1).reshape(-1, 3, config.image_height, config.image_width)\n",
    "        neg_action_enc = encoder1(positive_images, negative_dirs.view(-1, 2)).view(negative_dirs.shape[0], negative_dirs.shape[1], -1)\n",
    "        # print(f'full: {neg_action_enc.shape}')\n",
    "#         # print(negative_full.shape)\n",
    "#         neg_action_enc = encoder1(negative_full)\n",
    "#         # print(f'positive_enc: {positive_enc.shape}, anchor: {anchor_enc.shape}, neg_action_enc: {neg_action_enc.shape}')\n",
    "\n",
    "        if config.hyperbolic:\n",
    "            action_loss = hyperbolic_infoNCE_loss(positive_enc, anchor_enc, neg_action_enc, config.temperature, manifold=manifold)\n",
    "            future_loss = hyperbolic_infoNCE_loss(anchor_enc, positive_enc, negatives_enc, config.temperature, manifold=manifold)\n",
    "        else:\n",
    "            action_loss = infoNCE_loss(positive_enc, anchor_enc, neg_action_enc, config.temperature, metric_type=1)\n",
    "            future_loss = infoNCE_loss(anchor_enc, positive_enc, negatives_enc, config.temperature, metric_type=1)\n",
    "\n",
    "        loss = action_loss + future_loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    loss = total_loss / len(dataloader)\n",
    "\n",
    "    evals = evaluate(maze, config.eval_trials, encoder1, encoder2, manifold, config.image_height, config.image_width, max_steps=config.max_steps, hyperbolic=config.hyperbolic)\n",
    "    acc = np.mean([x[2] for x in evals])\n",
    "    fail = np.mean([x[0] for x in evals])\n",
    "\n",
    "    metrics = {\n",
    "        \"epoch\": epoch + 1,\n",
    "        \"loss\": loss,\n",
    "        \"spl\": acc,\n",
    "        \"fail\": fail\n",
    "    }\n",
    "\n",
    "    if acc > best_spl:\n",
    "        best_spl = acc\n",
    "        best_encoder1 = encoder1.state_dict()\n",
    "        best_encoder2 = encoder2.state_dict()\n",
    "        best_epoch = epoch + 1\n",
    "\n",
    "    print(f'Epoch {epoch+1}, Loss: {loss}, SPL: {acc}, Failure %: {fail}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6733b8b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'end' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m goal \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(get_maze_image(maze, \u001b[43mend\u001b[49m, image_height, image_width))\u001b[38;5;241m.\u001b[39mto(device, torch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'end' is not defined"
     ]
    }
   ],
   "source": [
    "goal = torch.tensor(get_maze_image(maze, end, image_height, image_width)).to(device, torch.float32).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f71daa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..255.0].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x153c60410820>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(positive.cpu()[3].moveaxis(0, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2143ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hypll [~/.conda/envs/hypll/]",
   "language": "python",
   "name": "conda_hypll"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
